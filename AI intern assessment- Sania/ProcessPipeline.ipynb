{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProcessPipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code for AI Developer Assesment Submitted By Sania Banga\n",
        "Let us assume that we have a dataset for training purposes with X features and y being the output. Let us assume we have a data with people walking and individual series of images have been used for training the model. For example we have a woman say \"Alex\". We record her features(Her speed and walk style) and state that the output is \"Alex\"."
      ],
      "metadata": {
        "id": "-SJDOezn-QkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*RCNN is used for the gat analysis. *"
      ],
      "metadata": {
        "id": "6AQlQecBCxDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd, seaborn as sns\n",
        "sns.set_style('white')\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import os,cv2,keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score,f1_score,recall_score,accuracy_score\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from PIL import Image\n",
        "#from google.colab.patches import cv2_imshow  \n",
        "from skimage import io"
      ],
      "metadata": {
        "id": "zoIiN7Hj_dYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
      ],
      "metadata": {
        "id": "nj9JqMOZ_iCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1['x1'] < bb1['x2']\n",
        "    assert bb1['y1'] < bb1['y2']\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "    x_left = max(bb1['x1'], bb2['x1'])\n",
        "    y_top = max(bb1['y1'], bb2['y1'])\n",
        "    x_right = min(bb1['x2'], bb2['x2'])\n",
        "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "metadata": {
        "id": "t01Lfm_7BmXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=[]\n",
        "train_labels=[]\n",
        "#Assuming we are trying to find the gait analysis for a human Alex. In case we have a datafile with more people we can make a list and find for all. For demo purposes, we are trying to find the gait analysis for Alex. \n",
        "for e,i in enumerate(os.listdir(annot)):\n",
        "    try:\n",
        "\n",
        "        if i.startswith(\"Alex\"):\n",
        "            filename = i.split(\".\")[0]+\".jpg\"\n",
        "            print(e,filename)#Assuming we have the file and path. \n",
        "            image = cv2.imread(os.path.join(path,filename))\n",
        "            df = pd.read_csv(os.path.join(annot,i))\n",
        "            gtvalues=[]\n",
        "            for row in df.iterrows():\n",
        "                x1 = int(row[1][0].split(\" \")[0])\n",
        "                y1 = int(row[1][0].split(\" \")[1])\n",
        "                x2 = int(row[1][0].split(\" \")[2])\n",
        "                y2 = int(row[1][0].split(\" \")[3])\n",
        "                gtvalues.append({\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2})\n",
        "            ss.setBaseImage(image)\n",
        "            ss.switchToSelectiveSearchFast()\n",
        "            ssresults = ss.process()\n",
        "            imout = image.copy()\n",
        "            counter = 0\n",
        "            falsecounter = 0\n",
        "            flag = 0\n",
        "            fflag = 0\n",
        "            bflag = 0\n",
        "            for e,result in enumerate(ssresults):\n",
        "                if e < 2000 and flag == 0:\n",
        "                    for gtval in gtvalues:\n",
        "                        x,y,w,h = result\n",
        "                        iou = get_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
        "                        if counter < 30:\n",
        "                            if iou > 0.70:\n",
        "                                timage = imout[y:y+h,x:x+w]\n",
        "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                                train_images.append(resized)\n",
        "                                train_labels.append(1)\n",
        "                                counter += 1\n",
        "                        else :\n",
        "                            fflag =1\n",
        "                        if falsecounter <30:\n",
        "                            if iou < 0.3:\n",
        "                                timage = imout[y:y+h,x:x+w]\n",
        "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                                train_images.append(resized)\n",
        "                                train_labels.append(0)\n",
        "                                falsecounter += 1\n",
        "                        else :\n",
        "                            bflag = 1\n",
        "                    if fflag == 1 and bflag == 1:\n",
        "                        print(\"inside\")\n",
        "                        flag = 1\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"error in \"+filename)\n",
        "        continue"
      ],
      "metadata": {
        "id": "CfZ_ou9ABu2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array(train_images)\n",
        "y_new = np.array(train_labels)"
      ],
      "metadata": {
        "id": "M2HDNFnsB8M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras import Model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vggmodel = VGG16(weights='imagenet', include_top=True)\n",
        "for layers in (vggmodel.layers)[:15]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel.layers[-2].output\n",
        "predictions = Dense(2, activation=\"softmax\")(X)\n",
        "model_final = Model(input = vggmodel.input, output = predictions)\n",
        "opt = Adam(lr=0.0001)\n",
        "model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ],
      "metadata": {
        "id": "Oz1-msY9CVyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "class MyLabelBinarizer(LabelBinarizer):\n",
        "    def transform(self, y):\n",
        "        Y = super().transform(y)\n",
        "        if self.y_type_ == 'binary':\n",
        "            return np.hstack((Y, 1-Y))\n",
        "        else:\n",
        "            return Y\n",
        "    def inverse_transform(self, Y, threshold=None):\n",
        "        if self.y_type_ == 'binary':\n",
        "            return super().inverse_transform(Y[:, 0], threshold)\n",
        "        else:\n",
        "            return super().inverse_transform(Y, threshold)\n",
        "lenc = MyLabelBinarizer()\n",
        "Y =  lenc.fit_transform(y_new)\n",
        "X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)"
      ],
      "metadata": {
        "id": "_YtTGRBDCbRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "traindata = trdata.flow(x=X_train, y=y_train)\n",
        "tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "testdata = tsdata.flow(x=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "_iZzMgv6Cdsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 10, epochs= 1000, validation_data= testdata, validation_steps=2, callbacks=[checkpoint,early])"
      ],
      "metadata": {
        "id": "wjyFub1UCqGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z=0\n",
        "for e,i in enumerate(os.listdir(path)):\n",
        "    if i.startswith(\"4\"):\n",
        "        z += 1\n",
        "        img = cv2.imread(os.path.join(path,i))\n",
        "        ss.setBaseImage(img)\n",
        "        ss.switchToSelectiveSearchFast()\n",
        "        ssresults = ss.process()\n",
        "        imout = img.copy()\n",
        "        for e,result in enumerate(ssresults):\n",
        "            if e < 2000:\n",
        "                x,y,w,h = result\n",
        "                timage = imout[y:y+h,x:x+w]\n",
        "                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                img = np.expand_dims(resized, axis=0)\n",
        "                out= model_final.predict(img)\n",
        "                if out[0][0] > 0.70:\n",
        "                    cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "        plt.figure()\n",
        "        plt.imshow(imout)\n",
        "        break"
      ],
      "metadata": {
        "id": "HZ9pTaPXCtAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}