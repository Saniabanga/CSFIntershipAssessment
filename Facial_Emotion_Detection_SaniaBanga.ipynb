{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial_Emotion_Detection_SaniaBanga.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DEMO submitted by Sania Banga\n",
        "This project combines facial and textual recognition models of emotion recognition to analyze a text and convert it into to its emotion recognised speech. Generally, a tone of the text we write is lagging emotions, I have tried to combine facial expressions with the typed text to understand a particular emotion that is depicted in the text and voice out the text using the recognised emotion. My focus is on real-time prediction of a personâ€™s emotion while typing with a good accuracy. This is a mini project that I feel could be used in the real worl to help make texting a lot more emotion centred. "
      ],
      "metadata": {
        "id": "rR0zOHbKEHen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzRD8-QhFq_4",
        "outputId": "47c8e9ab-e8ab-41cc-ce92-5e53604ad8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyttsx3==2.71\n",
        "pip install SpeechRecognition\n",
        "pip install comtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNmdge6z0D5b",
        "outputId": "3066237c-9858-4b99-d535-5c511ac82a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.7/dist-packages (2.90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install playsound\n",
        "pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWWBrLOK91GA",
        "outputId": "065c6bcf-07f2-4ed2-f4a3-d4e9a7d94be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygobject in /usr/lib/python3/dist-packages (3.26.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "\n",
        "text_to_speech = gTTS('I will say what you write')\n",
        "text_to_speech.save('TTS.mp3')\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHmetydY-Aa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playsound('TTS.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "-oD793wl-b1p",
        "outputId": "46ea5416-e006-487e-cc75-50dec8267f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8d5bddd42724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplaysound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TTS.mp3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/playsound.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sound, block)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mplaysound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_playsoundAnotherPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/bin/python3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacOS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/playsound.py\u001b[0m in \u001b[0;36m_playsoundAnotherPython\u001b[0;34m(otherPython, sound, block, macOS)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/playsound.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/playsound.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/playsound.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mplaysoundPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPropogatingThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherPython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaysoundPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_handlePathOSX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmacOS\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/usr/bin/python3', '/usr/local/lib/python3.7/dist-packages/playsound.py', 'TTS.mp3']' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "import datetime\n",
        "import speech_recognition as sr\n",
        "import random\n",
        "\n",
        "\n",
        "converter = pyttsx3.init()\n",
        "converter.setProperty('rate', 150)\n",
        "converter.say(\"Hello GeeksforGeeks\")\n",
        "converter.say(\"I'm also a geek\")\n",
        "converter.runAndWait()"
      ],
      "metadata": {
        "id": "__aV4oj6z4ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd, seaborn as sns\n",
        "sns.set_style('white')\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score,f1_score,recall_score,accuracy_score\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from PIL import Image\n",
        "#from google.colab.patches import cv2_imshow  \n",
        "from skimage import io"
      ],
      "metadata": {
        "id": "3Iq3FXXAL75A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Emotion_Recognition/train.csv')\n",
        "df.columns = [col.replace(\" \", \"\") for col in df.columns]\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Emotion_Recognition/test.csv')\n",
        "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25)\n"
      ],
      "metadata": {
        "id": "bzj42AomMBgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for index, row in training_data.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    \n",
        "    X_train.append(np.array(k))\n",
        "    y_train.append(row['emotion'])\n",
        "X_test = []\n",
        "y_test = []\n",
        "for index, row in testing_data.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    \n",
        "    X_test.append(np.array(k))\n",
        "    y_test.append(row['emotion'])\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "1o_KGugkMgyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d7c0e6f1-002d-44a4-b60d-c83b1cbe680a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ee53b740a539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')"
      ],
      "metadata": {
        "id": "ItKuSzpxNQFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "metadata": {
        "id": "WM6WCuSRODUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "datagen = ImageDataGenerator( \n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')\n",
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "uQkYnUVhOkPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Q8hvXttBOytZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "msAKLs0xO3aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "    \n",
        "    #the 5-th block\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model \n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "ngpaLJikPQ7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FER_Model()\n",
        "opt = Adam(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W6x1gSMPWBq",
        "outputId": "8d304bf8-6056-413a-ab49-e14c4571d405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 6, 6, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,111,367\n",
            "Trainable params: 13,103,431\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =   1\n",
        "history = model.fit_generator(train_flow, \n",
        "                    steps_per_epoch=len(X_train) / batch_size, \n",
        "                    epochs=num_epochs,  \n",
        "                    verbose=1,  \n",
        "                    validation_data=test_flow,\n",
        "                    validation_steps=len(X_test) / batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAU-0pazPbIc",
        "outputId": "b571d69c-3cc2-4289-8faf-7b52ec23259a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "358/358 [==============================] - 28s 78ms/step - loss: 0.2739 - accuracy: 0.8984 - val_loss: 1.5295 - val_accuracy: 0.6552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "#with open(\"model.json\", \"w\") as json_file:\n",
        "#    json_file.write(model_json)\n",
        "#model.save_weights(\"model.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUfgp_TpuIfU",
        "outputId": "aca8ca8b-a268-4496-adb9-a4e4ce8c2dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "model = model_from_json(open(\"model.json\", \"r\").read())\n",
        "model.load_weights('model.h5')"
      ],
      "metadata": {
        "id": "Up2nnhk_uUUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0UUebVzvlqd",
        "outputId": "41256623-1719-4cb9-d1ec-060e7a61ea96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "metadata": {
        "id": "BJhAcOTPue5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Sq-nnt1juwQM",
        "outputId": "ac2505b3-d428-48b3-fe23-2c5b9ba2b137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-contrib-python-headless\n",
            "  Downloading opencv_contrib_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.0 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54.0 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python-headless) (1.21.5)\n",
            "Installing collected packages: opencv-contrib-python-headless\n",
            "Successfully installed opencv-contrib-python-headless-4.5.5.64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "sLv5O6N30PMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CxfhDsuR7cOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghUlAJzKSjFT"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    var textdata;\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      \n",
        "      \n",
        "     \n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<button type=\"button\">Send Text!</button>';\n",
        "      \n",
        "      instruction.onclick = () => {shutdown = true; };\n",
        "      div.appendChild(instruction);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result\n",
        "              };\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "#  return(JSON.stringify(js))\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "zUjNeccs7-zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "dYIQNOg470GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model, model_from_json\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from IPython.display import Image\n",
        "import time\n",
        "video_stream()\n",
        "\n",
        "totalprob=[]\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "counter = 0 \n",
        "count=0\n",
        "model = model_from_json(open(\"model.json\", \"r\").read())\n",
        "model.load_weights('model.h5')\n",
        "# model = load_model('static\\Fer2013.h5')\n",
        "face_haar_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "t_end = time.time() + 10\n",
        "while time.time() < t_end:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    \n",
        "    \n",
        "    if not js_reply:\n",
        "        break\n",
        "    \n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    \n",
        "    if (counter==0):\n",
        "      val = input(\"Enter your value: \")\n",
        "      print(val)\n",
        "      counter+=1\n",
        "    \n",
        "    height, width , channel = img.shape\n",
        "    sub_img = img[0:int(height/6),0:int(width)]\n",
        "    bbox_array = np.ones(sub_img.shape, dtype=np.uint8)*0\n",
        "    black_rect = np.ones(sub_img.shape, dtype=np.uint8)*0\n",
        "    res = cv2.addWeighted(sub_img, 0.77, bbox_array,0.23, 0)\n",
        "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    FONT_SCALE = 0.8\n",
        "    FONT_THICKNESS = 2\n",
        "    lable_color = (10, 10, 255)\n",
        "    \n",
        "    lable_dimension = cv2.getTextSize(lable,FONT ,FONT_SCALE,FONT_THICKNESS)[0]\n",
        "    textX = int((res.shape[1] - lable_dimension[0]) / 2)\n",
        "    textY = int((res.shape[0] + lable_dimension[1]) / 2)\n",
        "    cv2.putText(res, lable, (textX,textY), FONT, FONT_SCALE, (0,0,0), FONT_THICKNESS)\n",
        "    gray_image= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_haar_cascade.detectMultiScale(gray_image )\n",
        "    for (x,y,w,h) in faces:\n",
        "      cv2.rectangle(bbox_array, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  2)\n",
        "      roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
        "      roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "      image_pixels = img_to_array(roi_gray)\n",
        "      image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
        "      image_pixels /= 255\n",
        "      predictions = model.predict(image_pixels)\n",
        "      totalprob.append(predictions)\n",
        "      max_index = np.argmax(predictions[0])\n",
        "      #print(totalprob)\n",
        "      emotion_detection = ('angry', 'angry', 'surprise', 'happy', 'sad', 'surprise', 'neutral')\n",
        "      emotion_prediction = emotion_detection[max_index]\n",
        "      \n",
        "      #print(predictions)\n",
        "      cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0,textY+22+5), FONT,0.7, lable_color,2)\n",
        "      lable_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0])*100,1))+ \"%\")\n",
        "      violation_text_dimension = cv2.getTextSize(lable_violation,FONT,FONT_SCALE,FONT_THICKNESS )[0]\n",
        "      violation_x_axis = int(res.shape[1]- violation_text_dimension[0])\n",
        "      cv2.putText(res, lable_violation, (violation_x_axis,textY+22+5), FONT,0.7, lable_color,2)\n",
        "    #pp=(js_video)\n",
        "    bbox_array[0:int(height/6),0:int(width)] = res\n",
        "    \n",
        "    # convert overlay of bbox into bytes\n",
        " \n",
        "    \n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "#print(pp)\n",
        "cv2.destroyAllWindows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sohh3RYg7fMq",
        "outputId": "eecb2f3b-98c6-4771-96b3-0cd7ad846f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    var textdata;\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      \n",
              "      \n",
              "     \n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<button type=\"button\">Send Text!</button>';\n",
              "      \n",
              "      instruction.onclick = () => {shutdown = true; };\n",
              "      div.appendChild(instruction);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result\n",
              "              };\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your value: I am happy\n",
            "I am happy\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32)]\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32)]\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32), array([[4.3352859e-04, 9.8141954e-06, 3.1832237e-02, 9.3538964e-01,\n",
            "        3.0170321e-02, 7.1562616e-05, 2.0928637e-03]], dtype=float32)]\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32), array([[4.3352859e-04, 9.8141954e-06, 3.1832237e-02, 9.3538964e-01,\n",
            "        3.0170321e-02, 7.1562616e-05, 2.0928637e-03]], dtype=float32), array([[3.0391113e-04, 6.5663903e-06, 1.8001229e-02, 9.6165180e-01,\n",
            "        1.7123550e-02, 1.0895913e-04, 2.8040106e-03]], dtype=float32)]\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32), array([[4.3352859e-04, 9.8141954e-06, 3.1832237e-02, 9.3538964e-01,\n",
            "        3.0170321e-02, 7.1562616e-05, 2.0928637e-03]], dtype=float32), array([[3.0391113e-04, 6.5663903e-06, 1.8001229e-02, 9.6165180e-01,\n",
            "        1.7123550e-02, 1.0895913e-04, 2.8040106e-03]], dtype=float32), array([[3.5462712e-04, 7.9186702e-06, 2.8561177e-02, 9.4438678e-01,\n",
            "        2.4106177e-02, 1.2219396e-04, 2.4612246e-03]], dtype=float32)]\n",
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32), array([[4.3352859e-04, 9.8141954e-06, 3.1832237e-02, 9.3538964e-01,\n",
            "        3.0170321e-02, 7.1562616e-05, 2.0928637e-03]], dtype=float32), array([[3.0391113e-04, 6.5663903e-06, 1.8001229e-02, 9.6165180e-01,\n",
            "        1.7123550e-02, 1.0895913e-04, 2.8040106e-03]], dtype=float32), array([[3.5462712e-04, 7.9186702e-06, 2.8561177e-02, 9.4438678e-01,\n",
            "        2.4106177e-02, 1.2219396e-04, 2.4612246e-03]], dtype=float32), array([[8.8029032e-05, 2.9151249e-06, 1.0674047e-02, 9.8386937e-01,\n",
            "        3.4945637e-03, 1.0971930e-04, 1.7614219e-03]], dtype=float32)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function destroyAllWindows>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((totalprob))\n",
        "print(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlVD2kyDeILj",
        "outputId": "aeccae4d-c000-4860-f310-4ba93d861a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[1.25344552e-03, 4.58004070e-05, 1.10619225e-01, 8.05996895e-01,\n",
            "        7.92726502e-02, 7.03246988e-05, 2.74168188e-03]], dtype=float32), array([[2.08705271e-04, 5.11111739e-06, 1.87547375e-02, 9.63665366e-01,\n",
            "        1.38826445e-02, 1.44924139e-04, 3.33851390e-03]], dtype=float32), array([[4.3352859e-04, 9.8141954e-06, 3.1832237e-02, 9.3538964e-01,\n",
            "        3.0170321e-02, 7.1562616e-05, 2.0928637e-03]], dtype=float32), array([[3.0391113e-04, 6.5663903e-06, 1.8001229e-02, 9.6165180e-01,\n",
            "        1.7123550e-02, 1.0895913e-04, 2.8040106e-03]], dtype=float32), array([[3.5462712e-04, 7.9186702e-06, 2.8561177e-02, 9.4438678e-01,\n",
            "        2.4106177e-02, 1.2219396e-04, 2.4612246e-03]], dtype=float32), array([[8.8029032e-05, 2.9151249e-06, 1.0674047e-02, 9.8386937e-01,\n",
            "        3.4945637e-03, 1.0971930e-04, 1.7614219e-03]], dtype=float32)]\n",
            "I am happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "av=[0,0,0,0,0,0,0]\n",
        "#print(len(totalprob))\n",
        "for i in range(0,len(totalprob)):\n",
        " \n",
        "  for j in range(0,7):\n",
        "    av[j]=totalprob[i][0][j]+av[j]\n",
        "for k in range(0,len(av)):\n",
        "  av[k]=av[k]/(len(totalprob))\n",
        "print(av)\n",
        "emotion_detection = ('angry','happy', 'sad', 'surprise', 'neutral')\n",
        "del av[1]\n",
        "del av[1]\n",
        "\n",
        "max_index = np.argmax(av)\n",
        "dfemotion = pd.DataFrame(av)\n",
        "dfemotion['label']=emotion_detection\n",
        "print(emotion_detection[max_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENJENyr7Sbju",
        "outputId": "6a9549d8-8879-403d-c0f6-87ad5e74b14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0004403744436179598, 1.3020984207893585e-05, 0.0364071085738639, 0.9324933091799418, 0.0280083177688842, 0.00010461397444790539, 0.00253328609202678]\n",
            "happy\n"
          ]
        }
      ]
    }
  ]
}